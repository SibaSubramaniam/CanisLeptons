{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_folder_name='data/historical_price_data/ADABTC'   #the folder where data is stored\n",
    "bar_type='time'             #type of bars possible_values: dollar,time,ticks,volume\n",
    "threshold=60              #threshold for the given type of bar\n",
    "\n",
    "#normalization\n",
    "before=True\n",
    "\n",
    "# Labels\n",
    "volatility_threshold=10    #threshold in bars for volatility which is standard deviation of returns\n",
    "sampling=False\n",
    "v_bars_duration=1           #threshold in bars for vertical_bars which denotes a dataframe in triple-barrier method\n",
    "barrier_conf=[1,1]          #stop loss and profit taking limits [0]denotes stop loss and [1]denotes profit taking\n",
    "min_return=0                #minimum values for return in triple-barrier method\n",
    "risk=0\n",
    "sign_label=True\n",
    "visualize_plot=False        #flag for visualizing plots\n",
    "\n",
    "# Features\n",
    "sma_period = [10, 20] # [10, 15, 20]\n",
    "ema_period = [10, 20] # [10, 15, 20]\n",
    "BB_period  = [15]\n",
    "rsi_period = [15]\n",
    "williamsr_period = [15]\n",
    "roc_period = [15]\n",
    "adl_period = [15]\n",
    "vpt_period = [0] # 0:  period is not required\n",
    "emv_period = [0] # 0:  period is not required\n",
    "\n",
    "feature_list = ['sma',      'ema',    'BB',       'rsi',     'williamsr',        'roc', \n",
    "                'adl',     'vpt',   'emv']   #feature list \n",
    "period_all =[sma_period, ema_period, BB_period, rsi_period, williamsr_period, roc_period, \n",
    "             adl_period, vpt_period, emv_period ]  # feature list period (change this if feature_list_changed)\n",
    "\n",
    "\n",
    "## Input Used\n",
    "pkl_rawData='save_runs/MAIN_df_' + data_folder_name[27:]   ## Load data pickle file name\n",
    "pkl_bars=\"save_runs/cstk_\"+bar_type+\"_\"+str(threshold)+'_'+data_folder_name[27:] ## create bars\n",
    "pkl_labels=pkl_bars+'_'+str(volatility_threshold)+\"_\"+str(v_bars_duration)+\"_\"+str(barrier_conf)+\"_\"+str(min_return)+\"_labels\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Necessary Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#loading and preprocessing\n",
    "from load_data.loadData import LoadData\n",
    "from preprocessing.preProcessData import PreProcessData\n",
    "from csticks.createcandleStick import createCandleStick\n",
    "\n",
    "#normalize \n",
    "from normalize.norm import Normalizer\n",
    "\n",
    "#labeling\n",
    "from labelling.labelgenerator import LabelGenerator\n",
    "\n",
    "\n",
    "# Features\n",
    "from feature.featureExtraction import FeatureExtraction\n",
    "from feature.featureExtractionVisual import FVisual\n",
    "from feature.featureVerifyVisual import VerifyFeature\n",
    "\n",
    "#model selection\n",
    "from mlmodel.split import Split\n",
    "from mlmodel.performanceMetrics import Metrics\n",
    "from mlmodel.mlclassfier import MLClassifier\n",
    "from mlmodel.sequential_bootstrap import sequentialBootstrap\n",
    "from mlmodel.analysis import Analyser\n",
    "from mlmodel.validation import Validation\n",
    "\n",
    "############################ Object Creation ############################\n",
    "#for normalization\n",
    "nl_data=Normalizer()\n",
    "\n",
    "# For Labels\n",
    "ld_data = LoadData()\n",
    "pp_data = PreProcessData()\n",
    "cstk_ob = createCandleStick()\n",
    "lbl_ob=LabelGenerator()\n",
    "\n",
    "# For Features\n",
    "fe_ob = FeatureExtraction()\n",
    "fe_vis = FVisual()\n",
    "fe_verify = VerifyFeature()\n",
    "\n",
    "# For ML\n",
    "split_ob = Split()\n",
    "metrics_ob = Metrics()\n",
    "model_ob = MLClassifier()\n",
    "sb_ob = sequentialBootstrap()\n",
    "an_ob = Analyser()\n",
    "val_ob = Validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    MAIN_df = pd.read_pickle(pkl_rawData)\n",
    "    \n",
    "except (OSError, IOError) as e:\n",
    "    print(e)\n",
    "    MAIN_df = ld_data.load_data_dir(data_folder_name)\n",
    "    MAIN_df['Price'] = MAIN_df.loc[:,['Close']]\n",
    "    MAIN_df.to_pickle(pkl_rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-30 12:29:00.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-30 12:30:00.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-30 12:31:00.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-30 12:32:00.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-30 12:33:00.000000</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date      Open      High       Low     Close  Volume  \\\n",
       "0  2017-11-30 12:29:00.000000  0.000009  0.000009  0.000009  0.000009  1064.0   \n",
       "1  2017-11-30 12:30:00.000000  0.000009  0.000009  0.000009  0.000009     0.0   \n",
       "2  2017-11-30 12:31:00.000000  0.000009  0.000009  0.000009  0.000009     0.0   \n",
       "3  2017-11-30 12:32:00.000000  0.000009  0.000009  0.000009  0.000009     0.0   \n",
       "4  2017-11-30 12:33:00.000000  0.000089  0.000089  0.000089  0.000089  1311.0   \n",
       "\n",
       "      Price  \n",
       "0  0.000009  \n",
       "1  0.000009  \n",
       "2  0.000009  \n",
       "3  0.000009  \n",
       "4  0.000089  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bars\n",
    "try:\n",
    "    cstk_df = pd.read_pickle(pkl_bars)\n",
    "except (OSError, IOError) as e:\n",
    "    print(e)\n",
    "    cstk_df = cstk_ob.createBars(MAIN_df,bar_type,threshold,0)\n",
    "    cstk_df.to_pickle(pkl_bars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateStop</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateStart</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:29:00</th>\n",
       "      <td>2017-11-30 12:29:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:30:00</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:31:00</th>\n",
       "      <td>2017-11-30 12:31:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:32:00</th>\n",
       "      <td>2017-11-30 12:32:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:33:00</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               DateStop      Open      High       Low  \\\n",
       "DateStart                                                               \n",
       "2017-11-30 12:29:00 2017-11-30 12:29:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:30:00 2017-11-30 12:30:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:31:00 2017-11-30 12:31:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:32:00 2017-11-30 12:32:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:33:00 2017-11-30 12:33:00  0.000089  0.000089  0.000089   \n",
       "\n",
       "                        Close  Volume     Price  \n",
       "DateStart                                        \n",
       "2017-11-30 12:29:00  0.000009  1064.0  0.000009  \n",
       "2017-11-30 12:30:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:31:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:32:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:33:00  0.000089  1311.0  0.000089  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    full_df = pd.read_pickle(pkl_labels)\n",
    "except (OSError, IOError) as e:\n",
    "    print(e)\n",
    "    full_df = lbl_ob.get_barrier_labels(cstk_df,sampling,volatility_threshold,v_bars_duration,\n",
    "                                        barrier_conf,min_return,risk,sign_label)\n",
    "    full_df.to_pickle(pkl_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  -1.0    110354\n",
      " 1.0    109748\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "positive=full_df[full_df['label']==1.0]\n",
    "negative=full_df[full_df['label']==-1.0]\n",
    "neutral=full_df[full_df['label']==0.0]\n",
    "\n",
    "non_zero_labels=full_df[full_df['label']!=0.0]\n",
    "print('Labels: ', non_zero_labels.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>type</th>\n",
       "      <th>vbars</th>\n",
       "      <th>ret</th>\n",
       "      <th>label</th>\n",
       "      <th>sharp_ratio</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateStart</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-07 09:57:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>tp</td>\n",
       "      <td>2018-06-07 09:58:00</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 09:58:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>sl</td>\n",
       "      <td>2018-06-07 09:59:00</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.506721</td>\n",
       "      <td>4.928039e+80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 09:59:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>t1</td>\n",
       "      <td>2018-06-07 10:00:00</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.698930</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:00:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>t1</td>\n",
       "      <td>2018-06-07 10:01:00</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.463048</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:01:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>tp</td>\n",
       "      <td>2018-06-07 10:02:00</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505503</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:02:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>t1</td>\n",
       "      <td>2018-06-07 10:03:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048636</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:03:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>sl</td>\n",
       "      <td>2018-06-07 10:04:00</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.935166e+80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:04:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>sl</td>\n",
       "      <td>2018-06-07 10:05:00</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.057406</td>\n",
       "      <td>4.935166e+80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:05:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000723</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>tp</td>\n",
       "      <td>2018-06-07 10:06:00</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.047734</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-07 10:06:00</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>t1</td>\n",
       "      <td>2018-06-07 10:07:00</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.374018</td>\n",
       "      <td>4.940519e+80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        close    return  volatility type               vbars  \\\n",
       "DateStart                                                                      \n",
       "2018-06-07 09:57:00  0.000028  0.000000    0.000490   tp 2018-06-07 09:58:00   \n",
       "2018-06-07 09:58:00  0.000028  0.000723    0.000480   sl 2018-06-07 09:59:00   \n",
       "2018-06-07 09:59:00  0.000028 -0.001444    0.000850   t1 2018-06-07 10:00:00   \n",
       "2018-06-07 10:00:00  0.000028  0.000362    0.000781   t1 2018-06-07 10:01:00   \n",
       "2018-06-07 10:01:00  0.000028  0.000361    0.000715   tp 2018-06-07 10:02:00   \n",
       "2018-06-07 10:02:00  0.000028  0.000723    0.000689   t1 2018-06-07 10:03:00   \n",
       "2018-06-07 10:03:00  0.000028  0.000000    0.000631   sl 2018-06-07 10:04:00   \n",
       "2018-06-07 10:04:00  0.000028 -0.000722    0.000683   sl 2018-06-07 10:05:00   \n",
       "2018-06-07 10:05:00  0.000028 -0.000723    0.000690   tp 2018-06-07 10:06:00   \n",
       "2018-06-07 10:06:00  0.000028  0.001085    0.000789   t1 2018-06-07 10:07:00   \n",
       "\n",
       "                          ret  label  sharp_ratio        profit  \n",
       "DateStart                                                        \n",
       "2018-06-07 09:57:00  0.000723    1.0     0.000000  0.000000e+00  \n",
       "2018-06-07 09:58:00 -0.001444   -1.0     1.506721  4.928039e+80  \n",
       "2018-06-07 09:59:00  0.000362    1.0    -1.698930  0.000000e+00  \n",
       "2018-06-07 10:00:00  0.000361    1.0     0.463048  0.000000e+00  \n",
       "2018-06-07 10:01:00  0.000723    1.0     0.505503  0.000000e+00  \n",
       "2018-06-07 10:02:00  0.000000    0.0     1.048636  0.000000e+00  \n",
       "2018-06-07 10:03:00 -0.000722   -1.0     0.000000  4.935166e+80  \n",
       "2018-06-07 10:04:00 -0.000723   -1.0    -1.057406  4.935166e+80  \n",
       "2018-06-07 10:05:00  0.001085    1.0    -1.047734  0.000000e+00  \n",
       "2018-06-07 10:06:00 -0.000361   -1.0     1.374018  4.940519e+80  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df=full_df.dropna()\n",
    "full_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateStop</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateStart</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:29:00</th>\n",
       "      <td>2017-11-30 12:29:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:30:00</th>\n",
       "      <td>2017-11-30 12:30:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:31:00</th>\n",
       "      <td>2017-11-30 12:31:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:32:00</th>\n",
       "      <td>2017-11-30 12:32:00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:33:00</th>\n",
       "      <td>2017-11-30 12:33:00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               DateStop      Open      High       Low  \\\n",
       "DateStart                                                               \n",
       "2017-11-30 12:29:00 2017-11-30 12:29:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:30:00 2017-11-30 12:30:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:31:00 2017-11-30 12:31:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:32:00 2017-11-30 12:32:00  0.000009  0.000009  0.000009   \n",
       "2017-11-30 12:33:00 2017-11-30 12:33:00  0.000089  0.000089  0.000089   \n",
       "\n",
       "                        Close  Volume     Price  \n",
       "DateStart                                        \n",
       "2017-11-30 12:29:00  0.000009  1064.0  0.000009  \n",
       "2017-11-30 12:30:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:31:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:32:00  0.000009     0.0  0.000009  \n",
       "2017-11-30 12:33:00  0.000089  1311.0  0.000089  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cstk_df['Date'] = cstk_df.index\n",
    "# cstk_df = cstk_df.reset_index()  ############ Code only works when first column name is DateStart and also\n",
    "                                 # there is no column with name Date\n",
    "cstk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-186f2a15a380>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rsi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe_ob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcstk_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'williamsr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/mlframework/v1/feature/featureExtraction.py\u001b[0m in \u001b[0;36mrsi\u001b[0;34m(self, df, col, period, dropna)\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m                                 \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4372\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4373\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4374\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4375\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \"\"\"\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_fdf = pd.DataFrame({'Close':cstk_df['Close']})\n",
    "full_fdf =  full_fdf.reset_index()\n",
    "full_fdf = full_fdf.rename(columns = {\"DateStart\": \"Date\"}) \n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    for j in range(len(period_all[i])):        \n",
    "        \n",
    "        if feature_list[i] == 'sma':\n",
    "            df_temp = fe_ob.simple_moving_avg(cstk_df,period_all[i][j],dropna=False)\n",
    "            \n",
    "        if feature_list[i] == 'ema':\n",
    "            df_temp = fe_ob.exp_moving_avg(cstk_df,period_all[i][j],dropna=False)\n",
    "            \n",
    "        if feature_list[i] == 'BB':\n",
    "            df_temp = fe_ob.bollinger_bands(cstk_df,period_all[i][j],dropna=False)\n",
    "            \n",
    "        if feature_list[i] == 'rsi':\n",
    "            df_temp = fe_ob.rsi(cstk_df, col='Price', period = period_all[i][j],dropna=False)\n",
    "            \n",
    "        if feature_list[i] == 'williamsr':\n",
    "            df_temp = fe_ob.willamsr(cstk_df,period = period_all[i][j])\n",
    "            \n",
    "        if feature_list[i] == 'roc':\n",
    "            df_temp = fe_ob.roc(cstk_df,col_name='Close',period = period_all[i][j], dropna=False)\n",
    "            \n",
    "        if feature_list[i] == 'adl':\n",
    "            df_temp = fe_ob.ad_oscillaor(cstk_df,period_all[i][j]) # check divisions\n",
    "        \n",
    "        if feature_list[i] == 'vpt':\n",
    "            df_temp = fe_ob.vpt(cstk_df,dropna=False)\n",
    "        \n",
    "        if feature_list[i] == 'emv':\n",
    "            df_temp = fe_ob.emv(cstk_df,dropna=False)\n",
    "        \n",
    "        # Adding Column to data frame\n",
    "        col_name_temp = feature_list[i] + '_' + str(period_all[i][j])         \n",
    "        if feature_list[i] == 'BB':\n",
    "            df_temp2 = pd.DataFrame({col_name_temp:df_temp[0]['Close']}) # Only adding BB up\n",
    "        else:\n",
    "            df_temp2 = pd.DataFrame({col_name_temp:df_temp['Close']})\n",
    "        full_fdf = pd.concat([full_fdf, df_temp2], axis=1)\n",
    "        \n",
    "    \n",
    "full_fdf=full_fdf.set_index('Date')\n",
    "\n",
    "# Adding labels to features\n",
    "a=full_fdf.index.searchsorted(non_zero_labels.index)\n",
    "df=full_fdf.iloc[a].dropna()\n",
    "df['label']=non_zero_labels.label\n",
    "df.head()\n",
    "\n",
    "# Saving Later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('saved_runs/unnormalised_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_pickle('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "df = df.dropna()\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X = pd.DataFrame(normalize(X))\n",
    "train_X, train_y, test_X, test_y = split_ob.train_test_split(X, y, 0.7) # split training-testing data\n",
    "\n",
    "#change v_bars to events['time']\n",
    "# indM = sb_ob.getIndMatrix(df.index, v_bars)\n",
    "# avgU = sb_ob.getAvgUniqueness(indM)\n",
    "# avgU = avgU.mean()\n",
    "\n",
    "# clf_RF, accuracy_RF = model_ob.ml_classfr(X, y, 1.0, 'RF', saveModel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = [5, 10, 15]\n",
    "for i in tt:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = i)\n",
    "    clf = clf.fit(train_X, train_y)\n",
    "    acc_train = clf.score(train_X, train_y)\n",
    "    acc_test = clf.score(test_X, test_y)\n",
    "    \n",
    "    print(i, ' train: ',  acc_train, ' test: ',  acc_test)\n",
    "    \n",
    "# We can clearly see from the result below that we are overfitting after depth = 10 for deecison tree.\n",
    "# So, our goal is to improve the test accuracy without overfittig and also not adding more data (for now).\n",
    "# Lets try ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X['Predicted']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree_depth = 10\n",
    "num_estimator = [10, 20, 50, 100]\n",
    "avgU = 1.\n",
    "\n",
    "for i in num_estimator:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = tree_depth)\n",
    "    clf = BaggingClassifier(base_estimator=clf,n_estimators=i, max_samples=avgU,max_features=1.) \n",
    "    clf_bag = clf.fit(train_X, train_y)\n",
    "    acc_train_bag = clf_bag.score(train_X, train_y)\n",
    "    acc_test_bag = clf_bag.score(test_X, test_y)\n",
    "    print(i, ' train: ',  acc_train_bag, ' test: ',  acc_test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see above that bagging helps us to improve the test accuracy a little bit and helps with overfitting. \n",
    "# Now what should be our next step. Let see if learning curve give us some indication about that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a quick experiment to test what will happen if tree_depth > 10. We can see from the results\n",
    "# that train accurancy is high, however test accuracy for above is better. SO tree_depth = 10 is good\n",
    "tree_depth = 15\n",
    "num_estimator = [10, 20, 50, 100]\n",
    "avgU = 1.\n",
    "\n",
    "for i in num_estimator:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = tree_depth)\n",
    "    clf = BaggingClassifier(base_estimator=clf,n_estimators=i, max_samples=avgU,max_features=1.) \n",
    "    clf_bag = clf.fit(train_X, train_y)\n",
    "    acc_train_bag = clf_bag.score(train_X, train_y)\n",
    "    acc_test_bag = clf_bag.score(test_X, test_y)\n",
    "    print(i, ' train: ',  acc_train_bag, ' test: ',  acc_test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf_bag.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth = 10\n",
    "num_etimator = 100 # we found above that this is a good number\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = tree_depth)\n",
    "clf_bag = BaggingClassifier(base_estimator=clf,n_estimators=num_etimator, max_samples=avgU,max_features=1.) \n",
    "val_ob.learning_curve(clf_bag, X, y, scoring='accuracy', n_splits=5) # Using X and y, not train_X and train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that there is still a bit of gap between train and test score above.\n",
    "# Let see if RF (that has more randomness than bagging) helps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=1,criterion='entropy',bootstrap=False,class_weight='balanced_subsample')\n",
    "\n",
    "tree_depth = 10\n",
    "num_estimator = [10, 20, 50, 100, 200, 300]\n",
    "avgU = 1.\n",
    "\n",
    "for i in num_estimator:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = tree_depth)\n",
    "    clf = RandomForestClassifier(n_estimators=i, criterion='entropy', max_depth = tree_depth,  max_features=None) \n",
    "    clf_RF = clf.fit(train_X, train_y)\n",
    "    acc_train_RF = clf_RF.score(train_X, train_y)\n",
    "    acc_test_RF = clf_RF.score(test_X, test_y)\n",
    "    print(i, ' train: ',  acc_train_RF, ' test: ',  acc_test_RF)\n",
    "    \n",
    "# The result below shows that test accuracy still can't be improved.\n",
    "# So, it means that bagging is best till now. Can we use max_feature hyperparamter\n",
    "# for improving RF further OR may be we can use boosting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next questions to consider\n",
    "# 1) For our case, there is a very small gap beteen train and test accuracy. We can \n",
    "# see that in our learning curves. This means that even if we increase the model complexity, \n",
    "# we may not be able to improve test accuracy. Thus, there is no point trying more fancier\n",
    "# classifiers. \n",
    "\n",
    "# Can you prove me wrong? Try other fancier classifiers and see if my conclusion is right. Please show the results\n",
    "# in our next meeting\n",
    "\n",
    "## Next Question: Based on my conclusion above we are only left with adding more data. Lets do that\n",
    "\n",
    "### Next question: I didn't use most of the things mentioned in the book. See what happens if we use that \n",
    "\n",
    "#### Next Question: Try the same excercise above with different metrics such as Profit, sharp ratio etc.\n",
    "\n",
    "##### Next Question :THis is specific for Siba: TRy the above exercise for ADABTC data and you will see that \n",
    "# it is overfitting very soon.Can you guess the reason. Hint : It has to do with volatility and the \n",
    "# profits defined by volatility.\n",
    "\n",
    "###### I expect all of you to think in such depth and then do these different experiments. This will not only\n",
    "# help the project but will also help you to learn and develop in-depth understanding about machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[X,y,y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,y]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
